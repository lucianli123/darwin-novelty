{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24db0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eeb4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://api.semanticscholar.org/graph/v1/paper/649def34f8be52c8b66281af98ae884c09aef38b/citations?fields=contexts,intents,isInfluential\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cbb277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847ef99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'offset': 0, 'next': 100, 'data': [{'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['background', 'methodology'], 'contexts': ['Meanwhile, both corporations [19] and non-profits [2] have indexed large swathes of the literature, often applying vision and NLP methods for not-always-accurate extraction of paper content and metadata [57].', 'In addition, Living Papers’ citation processor performs automatic lookup of bibliographic metadata from DOIs and other identifiers (e.g., PubMed and Semantic Scholar ids) to help ease reference management, while still supporting standard citation formats such as BibTeX.', 'Extraction tools include GROBID [37] and the infrastructure behind the open Semantic Scholar graph [2].', '…the CHI, UIST, VIS, and ASSETS communities; information extraction and knowledge base researchers (many associated with the Semantic Scholar team [2]); and publishing tool developers, including contributors to Quarto [49], Distill.pub [59], Nota [12], Jupyter [33], Observable [44], and the New…', 'All cite-ref nodes are updated to include an integer index into the sorted bibliography and a resolved id. 2 To support in-context reading aids and information extraction, bibliographic data (CSL-JSON, BibTeX, and Semantic Scholar data) are added to the article AST’s top-level data property under the citations key.', 'Over the period of a year we spoke with augmented reading and accessibility researchers from the CHI, UIST, VIS, and ASSETS communities; information extraction and knowledge base researchers (many associated with the Semantic Scholar team [2]); and publishing tool developers, including contributors to Quarto [49], Distill.pub [59], Nota [12], Jupyter [33], Observable [44], and the New York Times.', 'Given a resolved external id, the transform also queries the Semantic Scholar API [2] for additional information, including abstracts and summary (“tldr”) snippets.', 'While tools like Semantic Scholar rely on accurate information extraction to provide reading aids, Living Papers side-steps this issue via language design and enables downstream extraction by producing APIs to query paper content and reuse reactive web content.'], 'isInfluential': True}, {'intents': ['background'], 'contexts': ['Previous medical datasets have been collected from healthcare-related literature (Dernoncourt and Lee, 2017; Gupta et al., 2021; Jin et al., 2019b; Banarescu et al., 2013) or web pages on the Internet (McCreery et al., 2020; Ammar et al., 2018).'], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['Several studies have shown their interest in constructing the scientific knowledge graph [2, 28, 29, 41] by using authors, scholarly entities, advisor-advisee relationship, and citation relations.', 'For example, Ammar et al. [2] construct a literature graph where nodes are the entities, authors, and papers.'], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['∗Work completed during an internship at Semantic Scholar, Allen Institute for AI.\\nscientific documents — and other information spaces — through LLM-powered interactions.', ', Google Scholar [3] and Semantic Scholar [1]), graph-based visual tools (e.', '07 58\\nFok et al.\\nas Google Scholar1 and Semantic Scholar2 allow scholars to search for papers, navigate citation graphs, and receive recommended papers based on their interests.', 'We then used the Semantic Scholar Recommendations API10 to obtain 25 additional recommended papers for each participant based on their seed papers.', 'For instance, many scholars nowadays use systems such as paper search engines (e.g., Google Scholar [3] and Semantic Scholar [1]), graph-based visual tools (e.g., ConnectedPapers [56]), and information extraction tools (e.g., Elicit [18]) to assist in discovering relevant work or scaffolding a literature review.'], 'isInfluential': True}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['SemanticScholar Information from SemanticScholar is requested in a three-level query.', 'Weak Filtering The idea behind weak filtering is that titles and authors can change during publication, so publications that are directly linked to the preprint in literature databases (SemanticScholar and OpenAlex Step 1) contain more evidence than fuzzy matching.', 'It is based on the databases SemanticScholar [3, 25, 31], Google Scholar [20], CrossRef / CrossCite, NASA Astrophysics Data System (ADS) [2], and the Inspire HEP API [32].', '%) followed by SemanticScholar (48.7 %), CrossRef / CrossCite (46.8 %), and OpenAlex (29.9 %).', 'ArXiv-ids are often directly linked to published versions, and it is possible to request data directly using this id. 14 DBLP record statistics: https://dblp.org/statistics/recordsindblp.html,\\nAccessed: 2023-07-19 15 DBLP publication type statistics: https://dblp.org/statistics/distributionof\\npublicationtype.html, Accessed: 2023-07-19 16 DBLP API: https://dblp.org/faq/How+to+use+the+dblp+search+API.html,\\nAccessed: 2023-07-19 17 CrossRef: https://www.crossref.org/06members/53status.html, Accessed: 2023-\\n07-19 18 CrossRef API: https://www.crossref.org/documentation/retrieve-metadata/\\nrest-api/, Accessed: 2023-07-19 19 SemanticScholar: https://www.semanticscholar.org/, Accessed: 2023-07-19 20 SemanticScholar API: https://www.semanticscholar.org/product/api, Access:\\n2023-07-19', 'SemanticScholar [3, 25, 31] is a literature database released in 2015 by the Allen Institute for Artificial Intelligence.', 'For all databases, there were preprints that are individually identified (DBLP: 25; 2.5 %, CrossRef / CrossCite: 8; 0.8 %, SemanticScholar: 26; 2.6 %, OpenAlex: 5; 0.5 %).', 'If no valid reference is found in Step 1, and if a DOI is available, the SemanticScholar API is requested for the DOI using https://api.semantic scholar.org/graph/v1/paper/DOI:{DOI}.', 'The authors thank SemanticScholar for providing an API key that allows requesting at a higher rate limit.', 'The authors thank the literature databases CrossRef / CrossCite, DBLP, SemanticScholar, and OpenAlex for the use of open access APIs and availability of data.'], 'isInfluential': True}, {'intents': ['methodology'], 'contexts': ['01σ p-value Journal Citation [Ammar et al., 2018] 22688 474841 0.', 'E.2 Robustness to k in real data: Journal Citation network\\nIn this section, we examine a journal citation network derived from the Semantic Scholar dataset [Ammar et al., 2018], which comprises over 200 million academic publications.', '2 Robustness to k in real data: Journal Citation network In this section, we examine a journal citation network derived from the Semantic Scholar dataset [Ammar et al., 2018], which comprises over 200 million academic publications.'], 'isInfluential': True}, {'intents': ['background'], 'contexts': ['Public search engines and publication aggre-gators such as Google Scholar , Semantic Scholar [2], CORE [20], OpenAlex [35] and PubMed are becoming increasingly popular for allowing researchers to freely access the latest publications.'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['we use a dataset from the Semantic Scholar Open Research Corpus [16], which contains over 39 million research papers in computer science, with attributes such as author list and citations.', 'To corroborate the effectiveness of proposed approaches, we use a dataset from the Semantic Scholar Open Research Corpus [16], which contains over 39 million research papers in computer science, with attributes such as author list and citations.'], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['14M papers from Semantic Scholar, where 82% of the papers belong to the biomedical domain, while the remaining 18% pertain to computer science [12].'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['14M papers from Semantic scholar[93] corpus consists of 18% papers from the computer science domain and 82% from the broad biomedical domain Single TPU v3 with 8 cores A Pretrained Language Model for Scientific Text -'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['There are several well-known generic RKGs, such as Microsoft Academic Knowledge Graph [54], OpenAlex [55], Springer Nature SciGraph [56], Semantic Scholar Literature Graph [33], OpenAIRE ResearchGraph [57], [58], Research Graph [59], and Scholarly Link Exchange (Scholix) [60].', 'Besides well-known KGs for encyclopedic and factual data, such as DBpedia [31] and WikiData [32], using socalled Research Knowledge Graphs (RKGs) for scientific data is a rather new approach [28], [29], [33].', 'There are several well-known generic RKGs, such as Microsoft Academic Knowledge Graph [54], OpenAlex [55], Springer Nature SciGraph [56], Semantic Scholar Literature Graph [33], OpenAIRE ResearchGraph [57], [58], Research Graph [59], and Scholarly Link'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['The literature graph was created in [1] using nodes for articles, authors and scientific concepts.'], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['• SciBERT [2]1 is a scientific PLM trained on 1.14M scientific papers from Semantic Scholar [1] using masked language modeling and next sentence prediction tasks.', 'Second, the entire paper is long (e.g., with ∼4,000 words on average in the Semantic Scholar Open Research Corpus (S2ORC) [26]), which exceeds the maximum sequence length (e.g., 512 tokens) that a PLM can handle in most cases.', '14M scientific papers from Semantic Scholar [1] using masked language modeling and next sentence prediction tasks.'], 'isInfluential': True}, {'intents': ['background'], 'contexts': ['SciBERT (11) is a related model which was initialised from scratch and trained on full texts publications from the Semantic Scholar platform (20), and thus does not inherit any vocabulary from BERT making it potentially more useful for bioNLP tasks as it was trained on scientific publications from the biomedical domain (82%) and computer science (18%).'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['background', 'methodology'], 'contexts': ['We then considered a coauthorship complex from the Semantic Scholar Open Research Corpus [29] where nodes are authors and papers with k -authors are represented as k - simplices.', 'This is due to the piece-wise constant nature of the underlying edge flow with large discontinuity at these time instances [29].'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['To author-disambiguate the MEDLINE database, we used the disambiguation results provided by the PubMed Knowledge Graph 33 , which were obtained by combining information from the Author-ity disambiguation of PubMed 34 and the more recent Semantic Scholar database 35 .'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['…2019), have received increasing attention because they can be broadly applied to academic service platforms (Tang et al., 2008; Sinha et al., 2015; Ammar et al., 2018), and more importantly, uncover knowledge structures to accelerate scientific discovery (Naik et al., 2022; Chandak et al., 2023).'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['Example research directions include dataset creation (Ammar et al., 2018; Lo et al., 2020; Wang et al., 2020); modeling for tasks such as information extraction (Jain et al., 2020; Luan et al., 2018; Zhong and Chen, 2021; Hope In this work, we make possible the reporting of the state of NLP4SG,…'], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['S2ORC [29] is a large-scale academic paper corpus of articles in Semantic Scholar [ 1].'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['medical3, academic [3], or industrial [14]), while there has been no all-over-the-Internet', '[3] provided corpora of scientific documents together with a literature graph (defined as “a directed property graph which summarizes key information in the literature and can be used to answer the queries mentioned earlier as well as more complex queries”[3]).'], 'isInfluential': False}, {'intents': ['background', 'methodology'], 'contexts': ['For example, NICTA-PIBOSO extract and manually annotate only 1,000 abstracts from medical subdomains, although it has good quality, the quantity of this corpus is not enough to train the classification model, especially deep classification model, like Bert [13].', 'In: Proceedings of the Third International Joint Conference on Natural Language Processing, pp. 381–388 (2008) [29] Neumann, M., King, D., Beltagy, I., et al.: ScispaCy: fast and robust models for biomedical natural language processing. arXiv preprint arXiv 1902.07669 (2019) [30] Carletta, J.: Assessing Agreement on Classification Tasks: The Kappa Statistic.', 'In 2018, Cohan and Beltagy[13, 18] constructed CSAbstruct dataset collected from the Semantic Scholar corpus[13, 18], Which has 2,189 computer science abstracts (15 thousands sentences) and each sentence is manually annotated according to their rhetorical roles in the abstract.', 'In recent years, scholars have proposed different move recognition corpus of abstracts and full texts papers in different disciplines, and published a series of structured move corpora, such as NICTAPIBOSO[11], PubMed 200k RCT[12], CSAbstruct dataset[13], PubMed 380k[14], Emerald 110k[15], Fund project abstract move data[16].'], 'isInfluential': True}, {'intents': ['background'], 'contexts': ['’214 and Semantic Scholar data [2] from Oct.', 'Semantic Scholar [2] extracts paper content information, such as entities and mentions, which are used to construct a literature graph.', 'As for the system or tool to start with, multiple mentions were possible: Four described using Google, the same amount of people started the process by using Google Scholar.', 'Throughout their process, only five participants described using Google Scholar, four mentioned using Google.', 'The ACM DL, Bibsonomy [22], dblp [40], Google Scholar, Semantic Scholar [2], Springer Link, ResearchGate, Clarivate/Web of Science [50], Elsevier Scopus [50], and Dimensions [21] are DLs operating on bibliographic metadata which offer keyword-based search to retrieve and explore the underlying data.', 'As for the system or tool to start with, we did not encounter clear preferences: Four described using Google, three people started the process by using Google Scholar and dblp.', 'Classic bibliographic digital libraries (DLs) such as the ACM DL, Bibsonomy, dblp, Google Scholar, Semantic Scholar, SpringerLink, or ResearchGate support search and exploration functionality.', 'Throughout their process, over half (7) of the participants used Google Scholar, and the same amount incorporated a Google search.', 'As data source, we follow Kreutz et al. [33] and use the dblp XML dump from 1st Oct. ’21 4 and Semantic Scholar data [2] from Oct. ’21 for citations and AMiner Open Academic Graph 2.1 [52, 55, 61] for identifying automatically generated keywords of publications; abstracts are taken from both collections.'], 'isInfluential': True}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['● SciBERT [21]: a BERT model pre-trained on random Semantic Scholar articles [22].'], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['gov/pmc/) [19] that cover biomedical and computer science domains.'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['We deal with the author name disambiguation problem with the assistance of Semantic Scholar dataset3 (Ammar et al., 2018).'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['Ammar, W.; Groeneveld, D.; Bhagavatula, C.; Beltagy, I.; Crawford, M.; Downey, D.; Dunkelberger, J.; Elgohary, A.; Feldman, S.; Ha, V.; et al. Construction of the Literature Graph in Semantic Scholar.', 'Scibert [4] creates language models from the data of computer science and broad biomedical domain randomly sampled from Semantic Scholar [12].'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['SciBERT is a BERT-based pre-trained language model that was trained on a large corpus of scientific text from Semantic Scholar [41].'], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['A variety of academic service platforms, such as Google Scholar, AMiner [40], Microsoft Academic [38], Semantic Scholar [1], and PubMed [26], are available on the Web with great attention received.', 'A variety of academic service platforms, such as Google Scholar, AMiner [40], Microsoft Academic [38], Semantic Scholar [1], and'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['With coauthorship data in Ammar et al. (2018) we built an SC as Ebli et al. (2020) where nodes are authors and collaborations between k-authors are modeled as (k − 1)-simplices.', 'DATA PREPROCESSING We consider the data from the Semantic Scholar Open Research Corpus (Ammar et al., 2018) to construct a coauthorship complex where nodes are authors and collaborations between k-author are represented by (k − 1)-simplices.', 'With coauthorship data in Ammar et al. (2018) we built an SC as Ebli et al.', 'We consider the data from the Semantic Scholar Open Research Corpus (Ammar et al., 2018) to construct a coauthorship complex where nodes are authors and collaborations between k-author are represented by (k − 1)-simplices.'], 'isInfluential': True}, {'intents': ['methodology'], 'contexts': ['For the considered semantic information task, we consider the same parameters as in [54].'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['We collected all papers available for scientific scholars from DBLP for the Computer Science field, and from Semantic Scholar for the other fields [41, 42].'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['AI methods have been used to augment and accelerate current computational pipelines [2, 3, 4], including but not limited to virtual screening [5, 6], metabolic property prediction [7, 8, 9], and targeted chemical structure generation and editing [10, 11, 12, 13].'], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['1.14 million papers from Semantic Scholar [19] are randomly chosen for SciBERT training.', '14 million papers from Semantic Scholar [19] are randomly chosen for SciBERT training.'], 'isInfluential': True}, {'intents': ['methodology'], 'contexts': ['SciBERT makes use of the same architecture as BERT while being trained on scientific text corpus from Semantic Scholar [27].'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['We use a dataset from the Semantic Scholar Open Research Corpus [16], which contains over 39 million research papers with authors and citations.'], 'isInfluential': False}, {'intents': ['background', 'methodology'], 'contexts': ['Users can access our tool using their web browser without the need for any software installation, easily share their exploration results, and connect directly to Semantic Scholar’s live database of more than 200 million papers.', 'Users can right-click on a given paper multiple times to iteratively add five more of its citations (sorted by relevance, most influenced1, citation count, or recency) or references (by relevance, most influenced, or recency) [5] each time via the Exploration Dropdown (Figure 1D) menu2.', 'Due to Argo Scholar’s web-based deployment and live connection to the 200M papers on Semantic Scholar, we are able to evaluate the literature search approach based on incremental exploration with participants frommuch more diverse backgrounds and research experiences (Table 1) and at a scale that is a magnitude larger than previous studies [7, 13, 25].', 'We note that our usage of Semantic Scholar’s database may result in the inherent increased availability of papers in the sciences for our tool, so future workwill be focused on finding sources that supplement humanities research areas and implementing our participants’ suggestions.', 'Argo Scholar is tightly integrated with Semantic Scholar’s live data of over 200 million papers, enabling users to generate personalized literature exploration results in real-time through flexible, incremental exploration, a common and effective method for researchers to discover relevant work.', 'Users can add papers indexed by Semantic Scholar by either querying keywords related to their interests, entering a paper’s unique CorpusID (Figure 1B), or exploring citations and references based on select properties such as citation count or relevance (Figure 1D).', 'Developed using modern web technologies, Argo Scholar\\n1Citations that indicate that the cited work is used or extended in the new effort [27] 2Semantic Scholar supports 100 requests per 5 minutes per IP address\\nprovides users with new features critical for literature sensemaking (e.g., incremental exploration, live connection to Semantic Scholar’s Corpus API endpoint [19]) while inheriting Argo Lite’s core graph visualization capabilities built with React, Blueprint for UI, MobX state management, and Three.js WebGL graph rendering [18].', 'Through the Search Bar (Figure 1B), users can search for and add any of the 200 million plus papers indexed by Semantic Scholar by querying keywords or a paper title or inputting a specific paper’s unique CorpusID [19].', 'The Paper Information Panel (Figure 1C) shows key information for a highlighted or hovered-over paper, e.g., paper title, abstract, authors, citation count, publication venue, publication year, and the URL to its Semantic Scholar page (for full paper PDF, figures, etc.).', 'Participants in the humanities sometimes commented on a lack of papers available, which is indicative of the topics that Semantic Scholar may skew towards.', 'Argo Scholar connects to the live data of Semantic Scholar [5, 19] via its API, gaining access to its 205 million indexed papers (as of April 2022).'], 'isInfluential': True}, {'intents': ['background'], 'contexts': ['The shared large-scale datasets are suited for training and evaluating content-based personalization models and collaborativefiltering approaches, as we provide a rich set of metadata for each document and all the data to derive the user-document interactions, which could also be leveraged by citation prediction approaches [8].'], 'isInfluential': False}, {'intents': ['background', 'methodology'], 'contexts': [', which can only be used for model training related to search and recommendation [5], but not possible to be used to build a scientific knowledge base.', 'For example, Google Scholar [22], Semantic Scholar [5], and AceMap [54] are built based on literature, using natural language processing methods to classify the documents and extract features by parsing the documents to achieve the function of searching and recommending documents.'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['We identify these papers using the ACM’s reported DOIs, and link these to PDFs in the Semantic Scholar corpus [1].'], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['The Allen Institute for Artificial Intelligence (AI2) has released a large-scale academic knowledge graph in three fields: computer science, neuroscience, and biomedicine to promote more research in these spaces (Ammar et al., 2018).'], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['Some databases such as DrugBank [8], Therapeutic Target DB [9], and PharmGKB [10] are integrating to provide drug information including DDIs information for medical researchers and scientists.', 'For extraction of DDIs task, this dataset consists of DrugBank with 730 documents and MEDLINE with 175 abstracts.'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['The database of Connected Papers is connected to the Semantic Scholar Paper Corpus [40].', 'The database of Connected Papers is connected to the\\xa0Semantic Scholar Paper Corpus [40].'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['The approaches used in a scalable deployed production system for extracting structured information from scientific publications into the literature graph are presented in Construction of the Literature Graph in Semantic Scholar [9].'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['12, we randomly mask a subset of the tokens in the original texts in the AGENDA dataset to verify the robustness of the proposed semantic communication framework.', 'This figure is simulated using the AGENDA dataset.', 'The text datasets used to train the proposed APPO algorithm are the abstract generation dataset (AGENDA) [35] which consists of 40 thousand paper titles and abstracts from the proceedings of 12 top artificial intelligence conferences and the DocRED dataset [36] which consists of 5053 Wikipedia documents.'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['In [66], metadata is trained and passed to two layered bi-directional LSTM to accomplish entity extraction task.', 'A novel Abstract GENeration DAtaset (AGENDA) is created from Semantic Scholar corpus [66] to generate an abstract automatically.'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['Furthermore, we applied forward and backward snowballing to the identified primary studies [23]: First, we collected the references and citations using the Semantic Scholar Academic Graph API [24].'], 'isInfluential': False}, {'intents': ['background', 'methodology'], 'contexts': [', a case of polysemy)? Have they influenced each other? Which fields have been most influential to the evolution of this concept? Here, we address these questions by studying a corpus of scientific literature indexed by the Semantic Scholar open database [15].', 'To perform a large scale analysis of the academic literature, we exploit the possibility to access the publicly available Semantic Scholar Academic Graph (S2AG, pronounced “stag”), which provides monthly snapshots of research papers published in all fields [15].'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['The abstract generation dataset (AGENDA) [161], built with knowledge graphs extracted from articles in the proceedings of AI conferences [6] using SciIE [192], offers 40,000'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['We create a paper database consisting of all of the documents in the Semantic Search database [1] that are tagged as \"biology\", \"medicine\", or \"chemistry\" combined with the set of full papers from Pubmed Open Access.'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': ['3×107 7×107 Semantic Scholar (SC) [4] 6.'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['Connected diagram showing the selected investigations relating groundwater dynamics and sea-level rise to previous reviews, clustered by simulation tools (numerical models, geospatial data models and analytical models) and years of publications shown on the color scale from 2005 to 2020 with gray for prior work, modified from connected papers concepts (Ammar et al., 2018).'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['A subset of the Semantic Scholar Open Research Corpus dataset (Ammar et al., 2018) is used to train the model.'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['3185295 knowledge graph construction [3], [4], citation relationship'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['Oracle Details We assumed oracle splitting and oracle coreference resolution in order to distill the token-level labels to a list for the PubMedBERT baselines.', 'Assuming oracle splitting and coreference (a nontrivial task), PubMedBERT would still have issues with 10 further examples.', 'Since prior works report numbers combined over multiple classes, we re-run training on only the Intervention label using PubMedBERT-CRF.', 'For token and phrase-level classi-\\nfication, we used a PubMedBERT model topped with a CRF layer.', 'PubMedBERT with an additional classification layer (LSTM or CRF) achieves close to state-of-the-art performance on the full task (Gu et al., 2021).', 'We fine-tuned a PubMedBERT (Gu et al., 2021) model, a BERT variant that was pretrained on biomedical abstracts and full-text articles from PubMed, using learning rate 1e-5, weight decay 0.01, the AdamW optimizer (Loshchilov and Hutter, 2018), and batch size 4, using the BERTForMultipleChoice functionality in HuggingFace Transformers (Wolf et al., 2019).', 'For the PubMedBERT baseline, in order to distill the identified spans to a list of arms, we assume (i) oracle splitting of spans into arms (given a span describing multiple arms, we can correctly split the span) and (ii) near-oracle coreference resolution (given multiple spans describing the same arm, we can correctly merge).', 'As an example of oracle splitting, PubMedBERT assigned a 1 to the span “40, 120, and 240 s exposure to 3,000, 700, and 500mg l1 clove solution;” this span in fact contains three different arms, and we assume it can be perfectly split, since the required information is theoretically present in the identified span.', 'Relation Extraction Baseline We use the model from Shi and Lin (2019) for relation extraction on top of PubMedBERT.', 'Here we fine-tune PubMedBERT (Gu et al., 2021) and follow Lang et al. (2022a); details and hyperparameters are found in the appendix.', 'The spans recognized by PubMedBERT include “adjuvant concurrent chemotherapy”, “capecitabinebased concurrent chemotherapy”, “postoperative CRT of capecitabine with or without oxaliplatin”, “concurrent capecitabine and radiotherapy (CapCRT)” and “capecitabine and oxaliplatin plus radiotherapy (Cap-Oxa-CRT).”', 'On the MIMIC Reverse Substitution dataset, despite being transferred to a new domain, our weaklysupervised PubMedBERT model performs similarly to LMC (Adams et al., 2020), which was pre-trained specifically on the MIMIC distribution.', 'More recently, following BERT, many clinical and biomedical variations swiftly followed including ClinicalBERT, SciBERT, BioBERT, and PubMedBERT (Devlin et al., 2018; Alsentzer et al., 2019; Ammar et al., 2018; Lee et al., 2020; Gu et al., 2021).', 'This results in 176 training contexts for the PubMedBERT + CRF model.', 'On CASI, GPT-3 edit + R alone already clearly outperforms the LMC model on both metrics, and the addition of weak supervision with PubMedBERT further boosts this performance.', 'The three examples it missed were also missed by PubMedBERT.', 'Assuming the oracle splitting and coreference, PubMedBERT would still have issues with 10 further examples: two again included a common procedure as a third arm, four were missing control arms, one was missing a treatment arm, two arms required further domain knowledge to consolidate (e.g., that Ramipril is an ACE inhibitory therapy), and another required properly consolidating a therapy with no overlapping tokens.'], 'isInfluential': True}, {'intents': ['background'], 'contexts': ['In the zoomed-in ego-network of the term “machine_translation” (the left graph), Hyponym-\\nOf is meaningfully highlighted by its role linking “machine_translation” and its sibling nodes as the research tasks “speech_recognition,” and “natural_language_generation” to the parent node “NLP_problems.”', 'For example, BioCreative for PPI [42,43], protein-mutation associations [44], and gene–disease relations [45]; or BioNLP [46] for complex n-ary bio events.', 'ScienceIE [16], NLP-TDMS [20], SciREX [21], and ORKG-TDM [22].', 'The most frequently used corpora are GENETAG (full-text articles annotated with protein/gene entities) [29], JNLPBA (~2400 abstracts annotated with DNA, RNA, protein, cell type and cell line concepts) [30], GENIA (~200 Medline abstracts annotated with 36 different concepts from the Genia ontology and several levels of linguistic/semantic features) [31], NCBI disease corpus (793 abstracts annotated with diseases in the MeSH taxonomy) [32], CRAFT (the second largest corpus with 97 full-text papers annotated with over 4000 corpus) [33] linking to the NCBI Taxonomy, the Protein, Gene, Cell, Sequence ontologies etc. Finally, the MedMentions corpus [34] as the largest dataset with ~4000 abstracts with ~34,724 concepts from the UMLS ontology.', 'Thus apart from having an impact in the emerging field of the discovery of science graphs, the STEM-NER-60k corpus can have specific applications in higher-level NLP tasks including information extraction [53],\\nfactuality ascertainment of statements in knowledge base population [54], and question answering over linked data [55].', 'The high-level identification of entities in text is a staple of most modern NLP pipelines over commonsense knowledge.', 'There have been several initiatives in the NLP [18,25,60,61], and the Semantic Web [62,63], communities suggesting an increasing trend toward adoption of KGs for scientific articles.'], 'isInfluential': True}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': ['[2, 5]) and in scientific reading applications (e.'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['[2] introduced the Semantic Scholar Academic Graph (S2AG), a dataset accessible via an API3, that provides metadata on research papers published in all fields.'], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['[2], each of them being associated to one or several authors.'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['KGs such as Microsoft Academic Knowledge Graph [Färber, 2019], SciGraph [Yaman et al., 2019], the Literature Graph [Ammar et al., 2018] and the Semantic Scholar Open Research Corpus [Lo et al., 2020] underpin the search functionalities of academic search engines like Google Scholar, Microsoft…', 'KGs such as Microsoft Academic Knowledge Graph [Färber, 2019], SciGraph [Yaman et al., 2019], the Literature Graph [Ammar et al., 2018] and the Semantic Scholar Open Research Corpus [Lo et al., 2020] underpin the search functionalities of academic search engines like Google Scholar, Microsoft Academic and Semantic Scholar.'], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['(1) S2AMP Gold - A ground truth dataset drawn from multiple online sources containing known mentor-mentee pairs, and links to rich bibliographic records of the individuals in Semantic Scholar (S2)1 [1].'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['background', 'methodology'], 'contexts': ['Since the advent of ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019), the new pretrain-thenfinetune paradigm has brought great performance improvement and dominated the methodology research of the natural language processing (NLP) field.', 'BioELMo (Jin et al., 2019) is pretrained on biomedical corpora based on stacked bidirectional LSTM language model ELMo (Peters et al., 2018).', 'Since the advent of ELMo (Peters et al., 2018) and BERT (Devlin et al.', ', 2019) is pretrained on biomedical corpora based on stacked bidirectional LSTM language model ELMo (Peters et al., 2018).'], 'isInfluential': True}, {'intents': ['background'], 'contexts': ['The first corpus consists of a subset of 200,000 paper abstracts, belonging to the Semantic Scholar (S2) (Ammar et al. 2018) database, and more specifically, to a subset of papers which also belong to the PubMed (Wheeler et al.'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['background'], 'contexts': ['14M Semantic scholar papers [43] (18% from Computer science and 82% from biomedical domains).'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['S2ORC is constructed using data from the Semantic Scholar literature corpus [6], which derives papers from numerous sources: obtained directly from publishers, from resources such as Microsoft Academic Graph (MAG) [100], from various archives such as arXiv or PubMed, or crawled from the open Internet in the format of PDFs or LaTeX.'], 'isInfluential': False}, {'intents': ['methodology'], 'contexts': ['The utility of the SPECTER model is due to its general purpose representation of the scientific literature, trained on the Semantic Scholar Corpus [31] of over a hundred thousand articles with their citation information.'], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}, {'intents': [], 'contexts': [], 'isInfluential': False}]}\n"
     ]
    }
   ],
   "source": [
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2100872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
